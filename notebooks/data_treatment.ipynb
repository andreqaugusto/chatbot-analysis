{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we download the data from S3 and do some necessary data treatment to answer the proposed questions.\n",
    "\n",
    "We save a copy of the treated data as a `parquet` file in the `../files` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we install all the extra libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization & Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import all the necessary libraries. Notice that we are using the `python-dotenv` library installed above to import the `.env` file located in the parent folder as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import unicodedata\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "env_path = str(Path().resolve().parent / \".env\")\n",
    "\n",
    "load_dotenv(dotenv_path=env_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we connect to the Spark master container. Notice that we also load the packages needed to download data from Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.9/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b5e21858-ab93-42e9-80bf-4092d55882c0;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/dist-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.hadoop#hadoop-aws;3.2.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.563 in central\n",
      ":: resolution report :: resolve 108ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.563 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.2.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b5e21858-ab93-42e9-80bf-4092d55882c0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "22/09/23 21:41:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# per docs https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/index.html#Anonymous_Login_with_AnonymousAWSCredentialsProvider\n",
    "\n",
    "spark = SparkSession.builder.appName('chatbot').master('spark://spark:7077') \\\n",
    "    .config('spark.jars.packages','org.apache.hadoop:hadoop-aws:3.2.2,com.amazonaws:aws-java-sdk-bundle:1.11.563') \\\n",
    "    .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider') \\\n",
    "    .getOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we read the data itself from Amazon S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/23 21:41:20 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"sep\", \";\").option('header', 'true').csv(os.getenv('S3_FILE_PATH'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sanity check to see if the data was loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------------+--------------------+-----------+-----------------+-----+------+\n",
      "|   timestamp|           messageId|      conversationId|              userId|messageText|          channel|botId|source|\n",
      "+------------+--------------------+--------------------+--------------------+-----------+-----------------+-----+------+\n",
      "|1614567604.0|210c2f5f-f7b2-406...|40b54398-77db-481...|bf6a4d079b51b73fd...|    começar|         whatsapp| 1567|  user|\n",
      "|1614567608.0|dd331cbb-4e0c-4f1...|b68806b9-7e79-462...|b0e978871c376ef13...|        olá|         telegram| 1567|  user|\n",
      "|1614567643.0|bb0c5d93-ffc2-400...|8061e54e-6a39-405...|73c659979af4ae8df...|    começar|         telegram| 1567|  user|\n",
      "|1614567704.0|4dc4a6b7-535e-4c2...|23ba09a6-b744-466...|a0ab3c262eda9b9a1...|        Olá|         telegram| 1567|  user|\n",
      "|1614567740.0|643f087f-6a79-4fb...|1389b06a-1bdc-465...|ea0ebd01ce3123bf4...|        ola|facebook messeger| 1567|  user|\n",
      "|1614567794.0|80594787-d08f-498...|c5e8e013-8f54-4e0...|104512575bda25ae7...|  registrar|         telegram| 1567|  user|\n",
      "|1614567852.0|998f2154-a5dd-499...|882de74c-8e78-414...|12fec0577e4309bab...|  registrar|         telegram| 1567|  user|\n",
      "|1614567872.0|4b9f34ae-30c2-4f0...|17d4ebd3-645f-49d...|d104c211a0a2c7b55...|    Comecar|              sms| 1567|  user|\n",
      "|1614567970.0|fc52d14c-475e-4ef...|1831ce03-4752-437...|c87a510a447ffc957...|    Começar|         whatsapp| 1567|  user|\n",
      "|1614567986.0|a453b86f-121d-46c...|605127c4-4b18-485...|d3c3fad9f2b258817...|    Comecar|facebook messeger| 1567|  user|\n",
      "+------------+--------------------+--------------------+--------------------+-----------+-----------------+-----+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another sanity check: lets see if we have over 50000 rows as claimed by the documentation that was given to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 516642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f'Rows: {df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the data was loaded correctly. Let's save the file just to keep it safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.coalesce(1).write.parquet(\"/app/files/raw_data\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we loaded data from a `CSV` file, it is a best-practice to cast the data in their correct type.\n",
    "\n",
    "First, let's see the current schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- messageId: string (nullable = true)\n",
      " |-- conversationId: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- messageText: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- botId: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the provided documentation (and as we can see above), the `timestamp` column is in unix epoch. We will cast that column as a 'normal' timestamp and, to help our analysis, we are also going to create a `date` column based on that timestamp.\n",
    "\n",
    "One other column that we can cast to a different type is `botId`. As seen in the data snippet shown above, the data in this column can be casted as `integer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('botId', F.col('botId').cast(T.IntegerType())) \\\n",
    "    .withColumn('timestamp', F.from_unixtime('timestamp').cast(T.TimestampType())) \\\n",
    "    .withColumn('date', F.to_date('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- messageId: string (nullable = true)\n",
      " |-- conversationId: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- messageText: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- botId: integer (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data casted in their appropriated types, we will register this table in SparkSQL as `chatbot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('chatbot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before start cleaning the data, let's do some data profiling to check that some of our assumptions about the data are correct.\n",
    "\n",
    "First, let's see what are the messages sent from the `bot` source (e.g. what are the questions the Chatbot asks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+\n",
      "|botText                                                           |\n",
      "+------------------------------------------------------------------+\n",
      "|Quais são seus pokemons favoritos?                                |\n",
      "|Qual seu nome?                                                    |\n",
      "|Qual a sua cidade?                                                |\n",
      "|Qual a sua idade?                                                 |\n",
      "|Olá, eu sou o robô de cadastro de pokemon favorito, vamos começar?|\n",
      "+------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bot_text = spark.sql(\"SELECT DISTINCT messageText AS botText FROM chatbot WHERE source = 'bot'\")\n",
    "bot_text.createOrReplaceTempView('bot')\n",
    "bot_text.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information will greatly help our data cleaning.\n",
    "\n",
    "Now, let's see how many unique users we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|count(DISTINCT userId)|\n",
      "+----------------------+\n",
      "|                 50000|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(DISTINCT userId) FROM chatbot\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have exactly 50000 users! Let's see if we have any user that messaged the Chatbot more than once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userID|chats|\n",
      "+------+-----+\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT userID, COUNT(DISTINCT conversationId) AS chats FROM chatbot GROUP BY 1 HAVING chats > 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, each user messaged the Chatbot only once! This means that our final dataset should also have 50000 users.\n",
    "\n",
    "Finally, let's see if we have users that messaged the Chatbot around midnight - meaning that we may have two different dates for each conversation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------------+\n",
      "|conversationId                      |days_chatted|\n",
      "+------------------------------------+------------+\n",
      "|eb92107e-c316-4b36-89d0-53e81766eeca|2           |\n",
      "|f3617919-e96c-47cc-923b-f73262802698|2           |\n",
      "|737feb49-2823-4fec-b9e4-c903462ade72|2           |\n",
      "|6e5addb0-2ad0-4899-90ba-645357e96cec|2           |\n",
      "|2134ef44-9857-41f7-8915-5ed1c26e1266|2           |\n",
      "|942af949-7871-45d8-a6ed-782e35d3cb2b|2           |\n",
      "|d02a563a-f503-40cf-947d-86e7fca73994|2           |\n",
      "|7c67e8b1-e731-4b02-b45e-cf096a36f0f1|2           |\n",
      "|ec8c5139-1e2f-4e3d-b840-feef51e878d6|2           |\n",
      "|298b1be2-474a-47e3-8f88-999748e3d5d5|2           |\n",
      "|8b3dbc95-a826-41f4-8baf-c8383d628b20|2           |\n",
      "|3c517060-1c1c-4127-a2bd-018bca4d5b5f|2           |\n",
      "|29dae2d6-e94d-478e-b1c3-7478d9c3e022|2           |\n",
      "|65736689-8e68-4a22-afcf-5d99baad8e06|2           |\n",
      "|287e2811-30a5-4bc0-8623-7c2b01e57c86|2           |\n",
      "|6e785891-4ba4-429f-a7ef-9c0df5121594|2           |\n",
      "|66c7afd9-b7e1-4bcb-aaaf-8860635e925c|2           |\n",
      "|701c6a91-de31-482a-b7d0-f52082ccd9ad|2           |\n",
      "|9e0e6cb2-d2f7-4b82-9963-79a415a3ff4f|2           |\n",
      "|03021bb2-276f-49fb-852f-26525534a481|2           |\n",
      "+------------------------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT conversationId, COUNT(DISTINCT date) AS days_chatted FROM chatbot GROUP BY 1 HAVING days_chatted > 1').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we do. In any given metric, we are going to use the date the user **first interacted with the Chatbot** as reference (in other words, `min(date)`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do the heavy lifting. Given the Chatbot questions, our goal by the end of this notebook is to have a dataset where each row has all the data provided by the user in a conversation with the Chatbot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  **date**  | **userId** | **conversationId** | **channel** |      **favourite_pokemon**      | **age** |   **city**   |  **botId**  |\n",
    "|:----------:|:----------:|:------------------:|:-----------:|:-------------------------------:|:-------:|:------------:|:-----------:|\n",
    "| 2022-01-01 |      A     |          1         |     sms     | [bulbasaur,charmander,squirtle] |    31   |   sao paulo  |     100     |\n",
    "| 2022-01-01 |      B     |          2         |   whatsapp  |           [pikachu]             |    25   | porto alegre |     101     |\n",
    "|    ...     |     ...    |         ...        |     ...     |             ...                 |   ...   |     ...      |     ...     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are going to have **only one row** per user and conversation (since those two fields together are a unique identifier). Also, note that the `favourite_pokemon` column is a **array**. This will be useful for future analysis.\n",
    "\n",
    "Since the `userId`, `conversationId`, `channel` and `botId` are unique across each user interaction and the `date` can be easily calculated (using the earlier definition), we only need to extract the `favourite_pokemon` list and the `age` and `city` of each user. We will do that next by using the Chatbot questions as reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us to obtain the desired dimensions (`favourite_pokemon`, `age` and `city`), we are going to do some feature engineering first.\n",
    "\n",
    "We are going to build a table that is going to contain, in one column, **(almost) every question the bot asked** and, in another one, **only the users answers** for said question. We will save that table as `chatbot_treated`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------+-----+------+\n",
      "|      date|          timestamp|              userId|      conversationId|         messageText|   messageTextAnswer|          channel|botId|source|\n",
      "+----------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------+-----+------+\n",
      "|2021-03-12|2021-03-12 07:02:52|0001a55b006e0bada...|e40467df-6f1f-4c4...|   Qual a sua idade?|                  38|              sms| 1567|   bot|\n",
      "|2021-03-12|2021-03-12 09:43:15|0001a55b006e0bada...|e40467df-6f1f-4c4...|  Qual a sua cidade?|        campo grande|              sms| 1567|   bot|\n",
      "|2021-03-12|2021-03-12 11:17:30|0001a55b006e0bada...|e40467df-6f1f-4c4...|Quais são seus po...|fearow florges su...|              sms| 1567|   bot|\n",
      "|2021-03-12|2021-03-12 13:55:51|0001a55b006e0bada...|e40467df-6f1f-4c4...|      Qual seu nome?|              helena|              sms| 1567|   bot|\n",
      "|2021-04-19|2021-04-19 06:26:14|00037981db6fa4f24...|31fea68a-a79d-445...|  Qual a sua cidade?|            Brasília|        instagram| 1567|   bot|\n",
      "|2021-04-19|2021-04-19 08:17:31|00037981db6fa4f24...|31fea68a-a79d-445...|      Qual seu nome?|              Lorena|        instagram| 1567|   bot|\n",
      "|2021-04-19|2021-04-19 09:09:51|00037981db6fa4f24...|31fea68a-a79d-445...|Quais são seus po...|             ninjask|        instagram| 1567|   bot|\n",
      "|2021-04-19|2021-04-19 14:41:02|00037981db6fa4f24...|31fea68a-a79d-445...|   Qual a sua idade?|                  23|        instagram| 1567|   bot|\n",
      "|2021-04-15|2021-04-15 11:11:34|0004013912834f551...|b5d4e68c-177d-4fe...|   Qual a sua idade?|                  28|              sms| 1567|   bot|\n",
      "|2021-04-15|2021-04-15 12:32:37|0004013912834f551...|b5d4e68c-177d-4fe...|  Qual a sua cidade?|              Palmas|              sms| 1567|   bot|\n",
      "|2021-04-15|2021-04-15 14:23:45|0004013912834f551...|b5d4e68c-177d-4fe...|Quais são seus po...|carnivine hippopotas|              sms| 1567|   bot|\n",
      "|2021-04-15|2021-04-15 16:43:24|0004013912834f551...|b5d4e68c-177d-4fe...|      Qual seu nome?|         Maria Clara|              sms| 1567|   bot|\n",
      "|2021-04-02|2021-04-02 07:58:53|00052c60aafed1bee...|a4387219-be30-412...|   Qual a sua idade?|                  55|         whatsapp| 1567|   bot|\n",
      "|2021-04-02|2021-04-02 08:56:59|00052c60aafed1bee...|a4387219-be30-412...|      Qual seu nome?|           antonella|         whatsapp| 1567|   bot|\n",
      "|2021-04-02|2021-04-02 09:00:20|00052c60aafed1bee...|a4387219-be30-412...|  Qual a sua cidade?|              suzano|         whatsapp| 1567|   bot|\n",
      "|2021-04-02|2021-04-02 10:27:03|00052c60aafed1bee...|a4387219-be30-412...|Quais são seus po...|           electrode|         whatsapp| 1567|   bot|\n",
      "|2021-03-10|2021-03-10 14:19:48|0007a057c85be431b...|7957d94d-1639-451...|  Qual a sua cidade?|           boa vista|facebook messeger| 1567|   bot|\n",
      "|2021-03-10|2021-03-10 15:30:08|0007a057c85be431b...|7957d94d-1639-451...|Quais são seus po...|barboach, minun, ...|facebook messeger| 1567|   bot|\n",
      "|2021-03-10|2021-03-10 16:37:29|0007a057c85be431b...|7957d94d-1639-451...|   Qual a sua idade?|                  39|facebook messeger| 1567|   bot|\n",
      "|2021-03-10|2021-03-10 18:02:23|0007a057c85be431b...|7957d94d-1639-451...|      Qual seu nome?|             joaquim|facebook messeger| 1567|   bot|\n",
      "|2021-04-28|2021-04-28 09:00:56|0007ebdf52111b7f1...|de116548-c058-48c...|   Qual a sua idade?|                  30|facebook messeger| 1567|   bot|\n",
      "|2021-04-28|2021-04-28 09:46:51|0007ebdf52111b7f1...|de116548-c058-48c...|Quais são seus po...|         minior-blue|facebook messeger| 1567|   bot|\n",
      "|2021-04-28|2021-04-28 12:59:42|0007ebdf52111b7f1...|de116548-c058-48c...|      Qual seu nome?|             Gabriel|facebook messeger| 1567|   bot|\n",
      "|2021-04-28|2021-04-28 13:51:56|0007ebdf52111b7f1...|de116548-c058-48c...|  Qual a sua cidade?|       foz do iguacu|facebook messeger| 1567|   bot|\n",
      "|2021-04-30|2021-04-30 14:15:02|000b29832b77f1815...|2f2245f8-4505-42e...|   Qual a sua idade?|                  55|         telegram| 1567|   bot|\n",
      "|2021-04-30|2021-04-30 16:41:12|000b29832b77f1815...|2f2245f8-4505-42e...|Quais são seus po...|     keldeo-resolute|         telegram| 1567|   bot|\n",
      "|2021-04-30|2021-04-30 19:13:54|000b29832b77f1815...|2f2245f8-4505-42e...|      Qual seu nome?|           Guilherme|         telegram| 1567|   bot|\n",
      "|2021-04-30|2021-04-30 20:00:59|000b29832b77f1815...|2f2245f8-4505-42e...|  Qual a sua cidade?|              franca|         telegram| 1567|   bot|\n",
      "|2021-03-10|2021-03-10 10:47:54|000f08196eb55c0ad...|f1d8d0b0-3caf-4ac...|  Qual a sua cidade?|               serra|        instagram| 1567|   bot|\n",
      "|2021-03-10|2021-03-10 11:43:45|000f08196eb55c0ad...|f1d8d0b0-3caf-4ac...|Quais são seus po...|rapidash-galar, s...|        instagram| 1567|   bot|\n",
      "+----------+-------------------+--------------------+--------------------+--------------------+--------------------+-----------------+-----+------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# we build the \"sourceLag\" column to avoid having a two rows containing the same information\n",
    "# whenever the user sent more than one message to answer the Pokémon question. \n",
    "# For example, imagine that an user answered that their favourite Pokémon was pikachu, charmander and mew in three different messages.\n",
    "# Our dataset would look like this:\n",
    "#\n",
    "#      messageText      | messageTextAnswer | source | sourceLag\n",
    "# what is your pokémon? |     pikachu       |   bot  |   user \n",
    "#      pikachu          |      null         |  user  |   bot     <- row being excluded since this information was already given in the previous row \n",
    "#     charmander        |      null         |  user  |   user\n",
    "#        mew            |      null         |  user  |   user\n",
    "#\n",
    "# Having these two lines with 'pikachu' would affect our data aggregation later.\n",
    "\n",
    "df = spark.sql(\n",
    "    \"\"\"\n",
    "    WITH prep AS (\n",
    "    SELECT \n",
    "        date,\n",
    "        timestamp,\n",
    "        userId, \n",
    "        conversationId,\n",
    "        messageText,\n",
    "        CASE\n",
    "            WHEN source='bot' THEN LEAD(messageText) OVER (PARTITION BY userId ORDER BY timestamp ASC)\n",
    "            ELSE NULL\n",
    "        END AS messageTextAnswer,\n",
    "        channel,\n",
    "        botId,\n",
    "        source,\n",
    "        LAG(source) OVER (PARTITION BY userId ORDER BY timestamp ASC) AS sourceLag \n",
    "    FROM chatbot \n",
    "    )\n",
    "    \n",
    "    SELECT \n",
    "        date,\n",
    "        timestamp,\n",
    "        userId,\n",
    "        conversationId,\n",
    "        messageText,\n",
    "        messageTextAnswer,\n",
    "        channel,\n",
    "        botId,\n",
    "        source    \n",
    "    FROM prep\n",
    "    WHERE (messageTextAnswer IS NOT NULL OR sourceLag='user') AND messageTextAnswer NOT IN (SELECT botText FROM bot)\n",
    "    \"\"\")\n",
    "df.createOrReplaceTempView('chatbot_treated')\n",
    "df.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we don't have only bot questions in the `messageText` column because someone can give multiple answers to the Pokémon question (as said in the documentation) before the Chatbot replied. This is going to be fixed next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pokémon Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will fix the problem mentioned above by creating a separated `pokemon` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+------------------------------------+------------------------------------+\n",
      "|userId                          |conversationId                      |pokemon                             |\n",
      "+--------------------------------+------------------------------------+------------------------------------+\n",
      "|0001a55b006e0badacdd32412b1333bf|e40467df-6f1f-4c41-9a05-0a371218b568|fearow florges sudowoodo            |\n",
      "|00037981db6fa4f247d261420252db49|31fea68a-a79d-4457-b544-a3bcf217b288|ninjask                             |\n",
      "|0004013912834f551f715d07e75548ce|b5d4e68c-177d-4fe7-b5de-524fd441ec18|carnivine hippopotas                |\n",
      "|00052c60aafed1bee9aab35a7fe114c1|a4387219-be30-4126-bc93-65fa86c8a49b|electrode                           |\n",
      "|0007a057c85be431b676ed7f7de1ea97|7957d94d-1639-4510-a0b7-7caab7a05671|barboach, minun, necrozma-ultra     |\n",
      "|0007ebdf52111b7f142966d4365206ed|de116548-c058-48ce-9e4e-9db67cc9cc42|minior-blue                         |\n",
      "|000b29832b77f18153e9772ff686286b|2f2245f8-4505-42e3-8f65-503e9e7791a2|keldeo-resolute                     |\n",
      "|000f08196eb55c0ada6b215050036c8e|f1d8d0b0-3caf-4ac6-9ce2-5e21ec12b87e|rapidash-galar, shedinja, sharpedo  |\n",
      "|000fc4e4810212bef07e90f90ed878af|56e00a03-f955-4281-8667-a722c254bc05|poliwhirl                           |\n",
      "|0010bd3852ab651cbd975d3ae2e62b3a|9a381d74-c452-442a-86db-e827fdda056b|minior-red-meteor                   |\n",
      "|001517711040d5584ddf5549e05a223a|31bff8bc-ef74-4155-8a77-0cf00393dae2|venusaur-mega                       |\n",
      "|0015f8c7040d4c06d8754cba67bc17dd|8df1710b-9e62-4128-b9da-f94fb367f50d|swoobat, cloyster, necrozma-ultra   |\n",
      "|00176811d2ccd06a0513124fe7b4c282|7b42042c-0cb7-4ffb-ac8b-9d3dc4a73728|dubwool                             |\n",
      "|001cbc78812df569ae19a97658b76d39|be27cbbd-3eeb-497f-ae99-c16fd1bf7589|magearna-original                   |\n",
      "|001cd2df9d7965a77b1502dc34361fb6|61209972-207d-4084-9e57-3f400d15c6e1|gible                               |\n",
      "|001e5f94ea9780e48bd5cbef4487f9fe|21a86367-d480-4170-aaa8-6c44940ad7f5|minior-red-meteor                   |\n",
      "|00201f95692d7dd073d8caca6af99c86|91d0bffe-fa2e-4784-8c7f-f6875b68b68d|servine, growlithe, tentacool       |\n",
      "|002633769ce2d9bfa459d5faa2b542d9|84fc1c00-e84f-411d-adc0-3373fbf223f3|hakamo-o, excadrill                 |\n",
      "|002727175a6f262dc2e153354444609f|3b0f6a51-255f-4689-8af2-f164a83a90b4|goomy                               |\n",
      "|0028e4efeb626a7e850e07ea6a8ff1ca|03edc322-057d-4561-b1fa-772b9eb23c27|morpeko-hangry, hattrem             |\n",
      "|002bd67c793914ca96c7f9dccc997646|90c38fb5-1e9c-4e89-9970-1a159defc55c|trevenant                           |\n",
      "|002e2f81dd62983fe2ce411498612126|5a837a50-8b80-408a-aaa1-2c640522f824|togedemaru-totem uxie               |\n",
      "|003011408b8ffdaa3e84f2c471765401|d3892561-bf4c-496b-8d91-8886a6650a6e|charjabug, dragalge, indeedee-male  |\n",
      "|0034856b8d9f7e0f9172a9dfa90cc774|5f0efcaf-d249-4817-9bf2-56c3fe95f3ab|thievul, pikachu-sinnoh-cap, linoone|\n",
      "|0035b842d47dd1bc9dbbd868e615eded|4d69f183-80d2-48fd-84fb-a10b583680f9|scraggy solosis                     |\n",
      "|003640c4a9badb4716efa8b3a4addfd0|b6319d2b-f3e5-4e34-b700-0950cd12f857|ninetales, yveltal, carnivine       |\n",
      "|003846da6f931f195490c2cf7080f24d|89195af0-83ee-4fec-87c6-fb966b7aaea9|necrozma-dawn                       |\n",
      "|00397ca4be503f6b63e2c74b5b4c4455|084319fb-0e82-4bbe-a0ed-8cbc41c8cd88|espeon gorebyss                     |\n",
      "|003c426d46b086a3103c138b2f0cf6a5|9d56dff7-ad9b-43cd-a4a7-5686b72ca733|chatot, rotom-wash, giratina-altered|\n",
      "|00428c864d493284c51bf5559dd50193|e5b1ac42-d070-49e2-af97-c93a42b90ec8|tympole, muk, drakloak              |\n",
      "+--------------------------------+------------------------------------+------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pokemon = spark.sql(\"\"\"\n",
    "    WITH prep AS (\n",
    "    SELECT \n",
    "        userId,\n",
    "        conversationId,\n",
    "        CASE \n",
    "            WHEN messageTextAnswer IS NOT NULL THEN messageTextAnswer\n",
    "            ELSE messageText\n",
    "        END AS pokemon\n",
    "    FROM\n",
    "        chatbot_treated\n",
    "    WHERE \n",
    "        messageText= 'Quais são seus pokemons favoritos?' OR source='user'\n",
    "    )\n",
    "    SELECT * FROM prep\n",
    "\"\"\")\n",
    "\n",
    "pokemon.createOrReplaceTempView('pokemon')\n",
    "pokemon.show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, we have a `pokemon` column with Pokémons for each user and conversation. Note that we have rows with the same `userId` and `conversationId`; this happens because the `pokemon` column is just the **raw** data from the conversation (meaning that the user sent 2 or more separate messages, each one with only one Pokémon).\n",
    "\n",
    "In the next step we are going to fix this (by making each combination of `userId` and `conversationId` unique across each row). To do that, we leverage [Spark UDFs](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.functions.udf.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=T.ArrayType(elementType=T.StringType()))\n",
    "def pokemon_treatment(pokemon):\n",
    "    if ',' in pokemon:\n",
    "        return pokemon.replace(' ','').split(',')\n",
    "    else:\n",
    "        return pokemon.replace(' ',',').split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-----------------------------------------------+\n",
      "|userId                          |pokemon_list                                   |\n",
      "+--------------------------------+-----------------------------------------------+\n",
      "|0001a55b006e0badacdd32412b1333bf|[fearow, florges, sudowoodo]                   |\n",
      "|0002a74240acbcc71caa2ec9dc9ede30|[raikou, miltank, silvally]                    |\n",
      "|00037981db6fa4f247d261420252db49|[ninjask]                                      |\n",
      "|00052c60aafed1bee9aab35a7fe114c1|[electrode]                                    |\n",
      "|0007a057c85be431b676ed7f7de1ea97|[barboach, minun, necrozma-ultra]              |\n",
      "|0008aa3c55fe166fb0173c9a8ebf025a|[pidgeotto]                                    |\n",
      "|0008b5872bde10f0a64fddc114852262|[cacnea, cofagrigus]                           |\n",
      "|000b1797c1571ff8693064ea2bbdec48|[stunfisk-galar, gothitelle, lombre]           |\n",
      "|000b29832b77f18153e9772ff686286b|[keldeo-resolute]                              |\n",
      "|000b78cddafd33f0cf0be82e606eaabf|[calyrex]                                      |\n",
      "|000e2873ad640b5c9589d8e956aa5295|[claydol]                                      |\n",
      "|0010bd3852ab651cbd975d3ae2e62b3a|[minior-red-meteor]                            |\n",
      "|00110d07268a46afdaa0c76fce8cda1b|[copperajah, nidorina]                         |\n",
      "|00132808e34530253560d3aaea69f2f2|[nosepass]                                     |\n",
      "|0014235fb2263d8b8172222c3c9966ba|[houndour]                                     |\n",
      "|00167535c3ac8389cb4c18e47297733e|[geodude-alola]                                |\n",
      "|0016a48569e36408a9b4f09150a1e955|[rayquaza, stonjourner]                        |\n",
      "|001c80676d327d373d36d1aa2ec518b3|[murkrow]                                      |\n",
      "|001cbc78812df569ae19a97658b76d39|[magearna-original]                            |\n",
      "|00244bbdfb071ef1dbb7b7005f7d93b6|[crabrawler]                                   |\n",
      "|002727175a6f262dc2e153354444609f|[goomy]                                        |\n",
      "|00278d98ee07f867c180011a974e5225|[poochyena]                                    |\n",
      "|0028c4be8a2f9174cdef87dcf63f814d|[shaymin-land, unown, growlithe]               |\n",
      "|002bd8dc9f1c50c709d4eb3299e97dd2|[grimer]                                       |\n",
      "|003011408b8ffdaa3e84f2c471765401|[charjabug, dragalge, indeedee-male]           |\n",
      "|00301a1d14cb2436ca65b7c09527c0bb|[fraxure]                                      |\n",
      "|003327269f02d140f38c8881a1698bd3|[mantine, abomasnow-mega, minior-indigo-meteor]|\n",
      "|0035b842d47dd1bc9dbbd868e615eded|[scraggy, solosis]                             |\n",
      "|003640c4a9badb4716efa8b3a4addfd0|[ninetales, yveltal, carnivine]                |\n",
      "|003c426d46b086a3103c138b2f0cf6a5|[chatot, rotom-wash, giratina-altered]         |\n",
      "+--------------------------------+-----------------------------------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pokemon_treated = pokemon.select('userId','conversationId', 'pokemon', pokemon_treatment('pokemon').alias('pokemon_treated'))\n",
    "pokemon_treated = pokemon_treated.groupBy('userId','conversationId').agg(F.collect_list('pokemon_treated').alias('pokemon_list'))\n",
    "pokemon_treated = pokemon_treated.select('userId', F.flatten('pokemon_list').alias('pokemon_list'))\n",
    "pokemon_treated.createOrReplaceTempView('pokemon_treated')\n",
    "pokemon_treated.show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the `pokemon` column that we wanted: each row has all the Pokémons that an user answered in some conversation.\n",
    "\n",
    "As we can see below, the `pokemon_list` column is indeed a `array`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- pokemon_list: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pokemon_treated.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are doing the same for the other two things that the Chatbot asked the users about: `age` and `city`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select our users ages by using the corresponding Chatbot question as reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    userId,\n",
    "    conversationId,\n",
    "    CAST(messageTextAnswer AS integer) as age\n",
    "FROM chatbot_treated\n",
    "WHERE messageText='Qual a sua idade?'\n",
    "GROUP BY 1,2,3\n",
    "\"\"\")\n",
    "age.createOrReplaceTempView('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "| age|count|\n",
      "+----+-----+\n",
      "|null|    3|\n",
      "|  18| 1291|\n",
      "|  19| 1245|\n",
      "|  20| 1247|\n",
      "|  21| 1343|\n",
      "|  22| 1354|\n",
      "|  23| 1341|\n",
      "|  24| 1297|\n",
      "|  25| 1354|\n",
      "|  26| 1351|\n",
      "|  27| 1321|\n",
      "|  28| 1296|\n",
      "|  29| 1331|\n",
      "|  30| 1374|\n",
      "|  31| 1353|\n",
      "|  32| 1330|\n",
      "|  33| 1265|\n",
      "|  34| 1280|\n",
      "|  35| 1288|\n",
      "|  36| 1271|\n",
      "|  37| 1356|\n",
      "|  38| 1329|\n",
      "|  39| 1321|\n",
      "|  40| 1264|\n",
      "|  41| 1380|\n",
      "|  42| 1314|\n",
      "|  43| 1351|\n",
      "|  44| 1324|\n",
      "|  45| 1342|\n",
      "|  46| 1242|\n",
      "|  47| 1283|\n",
      "|  48| 1266|\n",
      "|  49| 1329|\n",
      "|  50| 1398|\n",
      "|  51| 1288|\n",
      "|  52| 1241|\n",
      "|  53| 1374|\n",
      "|  54| 1338|\n",
      "|  55| 1320|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT age, COUNT(*) AS count FROM age GROUP BY 1 ORDER BY 1\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 3 'false positives' in our `age` dataframe. Since this represents 3/50000 ~ 0.006% of our data - thus irrelevant for any business metric - we will filter them out from our final dataset.\n",
    "\n",
    "The `users_to_filter` dataset will contain all `userId` that should not be in the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_to_filter = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    userId\n",
    "FROM age\n",
    "WHERE age IS NULL\n",
    "\"\"\")\n",
    "users_to_filter.createOrReplaceTempView('users_to_filter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|userId                          |\n",
      "+--------------------------------+\n",
      "|7f90ccd2b68cc9e4a2bf5d2ddb293f58|\n",
      "|fbba7d7a4445bd91a5e7bd560a6b766e|\n",
      "|f753f32e057fe1ee68a16d8852521c94|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM users_to_filter\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we do the same for the `city` dimension. As we shall see below, we will need to do some more advanced treatment.\n",
    "\n",
    "First, let's select the cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    userId,\n",
    "    conversationId,\n",
    "    messageTextAnswer as city\n",
    "FROM chatbot_treated\n",
    "WHERE messageText='Qual a sua cidade?'\n",
    "GROUP BY 1,2,3\n",
    "\"\"\")\n",
    "city.createOrReplaceTempView('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT city)|\n",
      "+--------------------+\n",
      "|                 301|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT (DISTINCT city) FROM city\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above, we have about 300 different cities. Let's give them a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|city                 |\n",
      "+---------------------+\n",
      "|21                   |\n",
      "|Abaete               |\n",
      "|Abaeté               |\n",
      "|Americana            |\n",
      "|Ananindeua           |\n",
      "|Anapolis             |\n",
      "|Anápolis             |\n",
      "|Aracaju              |\n",
      "|Barueri              |\n",
      "|Bauru                |\n",
      "|Belem                |\n",
      "|Belo Horizonte       |\n",
      "|Belém                |\n",
      "|Betim                |\n",
      "|Blumenau             |\n",
      "|Boa Vista            |\n",
      "|Brasilia             |\n",
      "|Brasília             |\n",
      "|Camacari             |\n",
      "|Camaçari             |\n",
      "|Campina Grande       |\n",
      "|Campinas             |\n",
      "|Campo Grande         |\n",
      "|Campos               |\n",
      "|Canoas               |\n",
      "|Carapicuiba          |\n",
      "|Carapicuíba          |\n",
      "|Cariacica            |\n",
      "|Caruaru              |\n",
      "|Cascavel             |\n",
      "|Caucaia              |\n",
      "|Caxias do Sul        |\n",
      "|Contagem             |\n",
      "|Crato                |\n",
      "|Cuiaba               |\n",
      "|Cuiabá               |\n",
      "|Curitiba             |\n",
      "|Diadema              |\n",
      "|Feira de Santana     |\n",
      "|Florianopolis        |\n",
      "|Florianópolis        |\n",
      "|Fortaleza            |\n",
      "|Foz do Iguacu        |\n",
      "|Foz do Iguaçu        |\n",
      "|Franca               |\n",
      "|Goiania              |\n",
      "|Goiânia              |\n",
      "|Governador Valadares |\n",
      "|Gravatai             |\n",
      "|Gravataí             |\n",
      "|Guaruja              |\n",
      "|Guarujá              |\n",
      "|Guarulhos            |\n",
      "|Iguacu               |\n",
      "|Iguaçu               |\n",
      "|Imperatriz           |\n",
      "|Ipatinga             |\n",
      "|Itaquaquecetuba      |\n",
      "|Jaboatao             |\n",
      "|Jaboatão             |\n",
      "|Joao Pessoa          |\n",
      "|Joinvile             |\n",
      "|João Pessoa          |\n",
      "|Juazeiro do Norte    |\n",
      "|Juiz de Fora         |\n",
      "|Jundiai              |\n",
      "|Jundiaí              |\n",
      "|Limeira              |\n",
      "|Londrina             |\n",
      "|Macapa               |\n",
      "|Macapá               |\n",
      "|Maceio               |\n",
      "|Maceió               |\n",
      "|Manaus               |\n",
      "|Maraba               |\n",
      "|Marabá               |\n",
      "|Maringa              |\n",
      "|Maringá              |\n",
      "|Maua                 |\n",
      "|Mauá                 |\n",
      "|Mogi das Cruzes      |\n",
      "|Montes Claros        |\n",
      "|Mossoro              |\n",
      "|Mossoró              |\n",
      "|Natal                |\n",
      "|Niteroi              |\n",
      "|Niterói              |\n",
      "|Olinda               |\n",
      "|Osasco               |\n",
      "|Palmas               |\n",
      "|Parnamirim           |\n",
      "|Paulista             |\n",
      "|Pelotas              |\n",
      "|Petrolina            |\n",
      "|Petropolis           |\n",
      "|Petrópolis           |\n",
      "|Piracicaba           |\n",
      "|Ponta Grossa         |\n",
      "|Porto Alegre         |\n",
      "|Porto Velho          |\n",
      "|Praia Grande         |\n",
      "|Recife               |\n",
      "|Ribeirao Preto       |\n",
      "|Ribeirao das Neves   |\n",
      "|Ribeirão Prêto       |\n",
      "|Ribeirão das Neves   |\n",
      "|Rio Branco           |\n",
      "|Rio de Janeiro       |\n",
      "|Salvador             |\n",
      "|Santa Maria          |\n",
      "|Santo Andre          |\n",
      "|Santo André          |\n",
      "|Santos               |\n",
      "|Sao Bernardo do Campo|\n",
      "|Sao Goncalo          |\n",
      "|Sao Jose do Rio Preto|\n",
      "|Sao Jose dos Campos  |\n",
      "|Sao Jose dos Pinhais |\n",
      "|Sao Luis             |\n",
      "|Sao Paulo            |\n",
      "|Sao Vicente          |\n",
      "|Serra                |\n",
      "|Sorocaba             |\n",
      "|Sumare               |\n",
      "|Sumaré               |\n",
      "|Suzano               |\n",
      "|São Bernardo do Campo|\n",
      "|São Gonçalo          |\n",
      "|São José do Rio Prêto|\n",
      "|São José dos Campos  |\n",
      "|São José dos Pinhais |\n",
      "|São Luís             |\n",
      "|São Paulo            |\n",
      "|São Vicente          |\n",
      "|Taboao da Serra      |\n",
      "|Taboão da Serra      |\n",
      "|Taubate              |\n",
      "|Taubaté              |\n",
      "|Teresina             |\n",
      "|Uberaba              |\n",
      "|Uberlandia           |\n",
      "|Uberlândia           |\n",
      "|Viamao               |\n",
      "|Viamão               |\n",
      "|Vila Velha           |\n",
      "|Vitoria              |\n",
      "|Vitoria da Conquista |\n",
      "|Vitória              |\n",
      "|Vitória da Conquista |\n",
      "|Volta Redonda        |\n",
      "|abaete               |\n",
      "|abaeté               |\n",
      "|americana            |\n",
      "|ananindeua           |\n",
      "|anapolis             |\n",
      "|anápolis             |\n",
      "|aracaju              |\n",
      "|barueri              |\n",
      "|bauru                |\n",
      "|belem                |\n",
      "|belo horizonte       |\n",
      "|belém                |\n",
      "|betim                |\n",
      "|blumenau             |\n",
      "|boa vista            |\n",
      "|brasilia             |\n",
      "|brasília             |\n",
      "|camacari             |\n",
      "|camaçari             |\n",
      "|campina grande       |\n",
      "|campinas             |\n",
      "|campo grande         |\n",
      "|campos               |\n",
      "|canoas               |\n",
      "|carapicuiba          |\n",
      "|carapicuíba          |\n",
      "|cariacica            |\n",
      "|caruaru              |\n",
      "|cascavel             |\n",
      "|caucaia              |\n",
      "|caxias do sul        |\n",
      "|contagem             |\n",
      "|crato                |\n",
      "|cuiaba               |\n",
      "|cuiabá               |\n",
      "|curitiba             |\n",
      "|diadema              |\n",
      "|feira de santana     |\n",
      "|florianopolis        |\n",
      "|florianópolis        |\n",
      "|fortaleza            |\n",
      "|foz do iguacu        |\n",
      "|foz do iguaçu        |\n",
      "|franca               |\n",
      "|goiania              |\n",
      "|goiânia              |\n",
      "|governador valadares |\n",
      "|gravatai             |\n",
      "|gravataí             |\n",
      "|guaruja              |\n",
      "|guarujá              |\n",
      "|guarulhos            |\n",
      "|iguacu               |\n",
      "|iguaçu               |\n",
      "|imperatriz           |\n",
      "|ipatinga             |\n",
      "|itaquaquecetuba      |\n",
      "|jaboatao             |\n",
      "|jaboatão             |\n",
      "|joao pessoa          |\n",
      "|joinvile             |\n",
      "|joão pessoa          |\n",
      "|juazeiro do norte    |\n",
      "|juiz de fora         |\n",
      "|jundiai              |\n",
      "|jundiaí              |\n",
      "|limeira              |\n",
      "|londrina             |\n",
      "|macapa               |\n",
      "|macapá               |\n",
      "|maceio               |\n",
      "|maceió               |\n",
      "|manaus               |\n",
      "|maraba               |\n",
      "|marabá               |\n",
      "|maria clara          |\n",
      "|maria luiza          |\n",
      "|maringa              |\n",
      "|maringá              |\n",
      "|maua                 |\n",
      "|mauá                 |\n",
      "|mogi das cruzes      |\n",
      "|montes claros        |\n",
      "|mossoro              |\n",
      "|mossoró              |\n",
      "|natal                |\n",
      "|niteroi              |\n",
      "|niterói              |\n",
      "|olinda               |\n",
      "|osasco               |\n",
      "|palmas               |\n",
      "|parnamirim           |\n",
      "|paulista             |\n",
      "|pelotas              |\n",
      "|petrolina            |\n",
      "|petropolis           |\n",
      "|petrópolis           |\n",
      "|piracicaba           |\n",
      "|ponta grossa         |\n",
      "|porto alegre         |\n",
      "|porto velho          |\n",
      "|praia grande         |\n",
      "|recife               |\n",
      "|ribeirao das neves   |\n",
      "|ribeirao preto       |\n",
      "|ribeirão das neves   |\n",
      "|ribeirão prêto       |\n",
      "|rio branco           |\n",
      "|rio de janeiro       |\n",
      "|salvador             |\n",
      "|santa maria          |\n",
      "|santo andre          |\n",
      "|santo andré          |\n",
      "|santos               |\n",
      "|sao bernardo do campo|\n",
      "|sao goncalo          |\n",
      "|sao jose do rio preto|\n",
      "|sao jose dos campos  |\n",
      "|sao jose dos pinhais |\n",
      "|sao luis             |\n",
      "|sao paulo            |\n",
      "|sao vicente          |\n",
      "|serra                |\n",
      "|sorocaba             |\n",
      "|sumare               |\n",
      "|sumaré               |\n",
      "|suzano               |\n",
      "|são bernardo do campo|\n",
      "|são gonçalo          |\n",
      "|são josé do rio prêto|\n",
      "|são josé dos campos  |\n",
      "|são josé dos pinhais |\n",
      "|são luís             |\n",
      "|são paulo            |\n",
      "|são vicente          |\n",
      "|taboao da serra      |\n",
      "|taboão da serra      |\n",
      "|taubate              |\n",
      "|taubaté              |\n",
      "|teresina             |\n",
      "|uberaba              |\n",
      "|uberlandia           |\n",
      "|uberlândia           |\n",
      "|viamao               |\n",
      "|viamão               |\n",
      "|vila velha           |\n",
      "|vitoria              |\n",
      "|vitoria da conquista |\n",
      "|vitória              |\n",
      "|vitória da conquista |\n",
      "|volta redonda        |\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT city FROM city ORDER BY 1\").show(305, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that, as the documentation said, we have cities with different spellings. However, it seems that all of the different spellings **do not** misspell - accents excluded - the cities name; for example, for the city of São Paulo we seem to only have the variations 'Sao Paulo', 'são paulo' and 'sao paulo').\n",
    "\n",
    "So, if we transform all city names to lowercase without accent (e.g. São Paulo -> sao paulo) we will fix all of those different spellings. \n",
    "\n",
    "Once again, to do such transformation, we will make use of Spark UDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf\n",
    "def city_treatment(city):\n",
    "    if city:\n",
    "        city = city.lower()\n",
    "        normalized = unicodedata.normalize(\"NFD\", city)\n",
    "        decoded = normalized.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "        return decoded\n",
    "    else:\n",
    "        return city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                city|\n",
      "+--------------------+\n",
      "|                  21|\n",
      "|              abaete|\n",
      "|           americana|\n",
      "|          ananindeua|\n",
      "|            anapolis|\n",
      "|             aracaju|\n",
      "|             barueri|\n",
      "|               bauru|\n",
      "|               belem|\n",
      "|      belo horizonte|\n",
      "|               betim|\n",
      "|            blumenau|\n",
      "|           boa vista|\n",
      "|            brasilia|\n",
      "|            camacari|\n",
      "|      campina grande|\n",
      "|            campinas|\n",
      "|        campo grande|\n",
      "|              campos|\n",
      "|              canoas|\n",
      "|         carapicuiba|\n",
      "|           cariacica|\n",
      "|             caruaru|\n",
      "|            cascavel|\n",
      "|             caucaia|\n",
      "|       caxias do sul|\n",
      "|            contagem|\n",
      "|               crato|\n",
      "|              cuiaba|\n",
      "|            curitiba|\n",
      "|             diadema|\n",
      "|    feira de santana|\n",
      "|       florianopolis|\n",
      "|           fortaleza|\n",
      "|       foz do iguacu|\n",
      "|              franca|\n",
      "|             goiania|\n",
      "|governador valadares|\n",
      "|            gravatai|\n",
      "|             guaruja|\n",
      "|           guarulhos|\n",
      "|              iguacu|\n",
      "|          imperatriz|\n",
      "|            ipatinga|\n",
      "|     itaquaquecetuba|\n",
      "|            jaboatao|\n",
      "|         joao pessoa|\n",
      "|            joinvile|\n",
      "|   juazeiro do norte|\n",
      "|        juiz de fora|\n",
      "|             jundiai|\n",
      "|             limeira|\n",
      "|            londrina|\n",
      "|              macapa|\n",
      "|              maceio|\n",
      "|              manaus|\n",
      "|              maraba|\n",
      "|         maria clara|\n",
      "|         maria luiza|\n",
      "|             maringa|\n",
      "|                maua|\n",
      "|     mogi das cruzes|\n",
      "|       montes claros|\n",
      "|             mossoro|\n",
      "|               natal|\n",
      "|             niteroi|\n",
      "|              olinda|\n",
      "|              osasco|\n",
      "|              palmas|\n",
      "|          parnamirim|\n",
      "|            paulista|\n",
      "|             pelotas|\n",
      "|           petrolina|\n",
      "|          petropolis|\n",
      "|          piracicaba|\n",
      "|        ponta grossa|\n",
      "|        porto alegre|\n",
      "|         porto velho|\n",
      "|        praia grande|\n",
      "|              recife|\n",
      "|  ribeirao das neves|\n",
      "|      ribeirao preto|\n",
      "|          rio branco|\n",
      "|      rio de janeiro|\n",
      "|            salvador|\n",
      "|         santa maria|\n",
      "|         santo andre|\n",
      "|              santos|\n",
      "|sao bernardo do c...|\n",
      "|         sao goncalo|\n",
      "|sao jose do rio p...|\n",
      "| sao jose dos campos|\n",
      "|sao jose dos pinhais|\n",
      "|            sao luis|\n",
      "|           sao paulo|\n",
      "|         sao vicente|\n",
      "|               serra|\n",
      "|            sorocaba|\n",
      "|              sumare|\n",
      "|              suzano|\n",
      "|     taboao da serra|\n",
      "|             taubate|\n",
      "|            teresina|\n",
      "|             uberaba|\n",
      "|          uberlandia|\n",
      "|              viamao|\n",
      "|          vila velha|\n",
      "|             vitoria|\n",
      "|vitoria da conquista|\n",
      "|       volta redonda|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city = city.withColumn('city', city_treatment('city'))\n",
    "city.createOrReplaceTempView('city')\n",
    "city.select('city').distinct().orderBy(F.asc('city')).show(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of the odd city `21` our transformation seems to be worked.\n",
    "\n",
    "Now we add the corresponding `userId` of the city `21` to our `users_to_filter` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              userId|\n",
      "+--------------------+\n",
      "|d4aa22a26cbcbc560...|\n",
      "|7f90ccd2b68cc9e4a...|\n",
      "|fbba7d7a4445bd91a...|\n",
      "|f753f32e057fe1ee6...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_to_filter = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    userId\n",
    "FROM city\n",
    "WHERE city = 21\n",
    "UNION\n",
    "SELECT userId FROM users_to_filter\n",
    "\"\"\")\n",
    "users_to_filter.createOrReplaceTempView('users_to_filter')\n",
    "users_to_filter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the Pokémon dimension treated and the `city` and `age` dimensions extracted, we can build our final dataframe. Notice that we are excluding the 4 users from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 134:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+-----------------+--------------------+---+-----------------+-----+\n",
      "|      date|              userId|      conversationId|          channel|   favourite_pokemon|age|             city|botId|\n",
      "+----------+--------------------+--------------------+-----------------+--------------------+---+-----------------+-----+\n",
      "|2021-03-12|0001a55b006e0bada...|e40467df-6f1f-4c4...|              sms|[fearow, florges,...| 38|     campo grande| 1567|\n",
      "|2021-04-19|00037981db6fa4f24...|31fea68a-a79d-445...|        instagram|           [ninjask]| 23|         brasilia| 1567|\n",
      "|2021-04-15|0004013912834f551...|b5d4e68c-177d-4fe...|              sms|[carnivine, hippo...| 28|           palmas| 1567|\n",
      "|2021-04-02|00052c60aafed1bee...|a4387219-be30-412...|         whatsapp|         [electrode]| 55|           suzano| 1567|\n",
      "|2021-03-10|0007a057c85be431b...|7957d94d-1639-451...|facebook messeger|[barboach, minun,...| 39|        boa vista| 1567|\n",
      "|2021-04-28|0007ebdf52111b7f1...|de116548-c058-48c...|facebook messeger|       [minior-blue]| 30|    foz do iguacu| 1567|\n",
      "|2021-04-30|000b29832b77f1815...|2f2245f8-4505-42e...|         telegram|   [keldeo-resolute]| 55|           franca| 1567|\n",
      "|2021-03-10|000f08196eb55c0ad...|f1d8d0b0-3caf-4ac...|        instagram|[rapidash-galar, ...| 49|            serra| 1567|\n",
      "|2021-04-09|000fc4e4810212bef...|56e00a03-f955-428...|         telegram|         [poliwhirl]| 25|            natal| 1567|\n",
      "|2021-03-01|0010bd3852ab651cb...|9a381d74-c452-442...|         telegram| [minior-red-meteor]| 18|      sao goncalo| 1567|\n",
      "|2021-03-18|001517711040d5584...|31bff8bc-ef74-415...|        instagram|     [venusaur-mega]| 19|         sao luis| 1567|\n",
      "|2021-04-19|0015f8c7040d4c06d...|8df1710b-9e62-412...|facebook messeger|[swoobat, cloyste...| 45|          uberaba| 1567|\n",
      "|2021-03-24|00176811d2ccd06a0...|7b42042c-0cb7-4ff...|              sms|           [dubwool]| 39|          niteroi| 1567|\n",
      "|2021-04-02|001cbc78812df569a...|be27cbbd-3eeb-497...|              sms| [magearna-original]| 41|           canoas| 1567|\n",
      "|2021-03-27|001cd2df9d7965a77...|61209972-207d-408...|              sms|             [gible]| 48|           sumare| 1567|\n",
      "|2021-04-12|001e5f94ea9780e48...|21a86367-d480-417...|         whatsapp| [minior-red-meteor]| 21|juazeiro do norte| 1567|\n",
      "|2021-04-06|00201f95692d7dd07...|91d0bffe-fa2e-478...|         telegram|[servine, growlit...| 24|          aracaju| 1567|\n",
      "|2021-03-13|002633769ce2d9bfa...|84fc1c00-e84f-411...|         telegram|[hakamo-o, excadr...| 22|      santa maria| 1567|\n",
      "|2021-04-24|002727175a6f262dc...|3b0f6a51-255f-468...|         whatsapp|             [goomy]| 33|          barueri| 1567|\n",
      "|2021-03-20|0028e4efeb626a7e8...|03edc322-057d-456...|        instagram|[morpeko-hangry, ...| 21|      porto velho| 1567|\n",
      "+----------+--------------------+--------------------+-----------------+--------------------+---+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final = spark.sql(\"\"\"\n",
    "WITH users AS (\n",
    "SELECT\n",
    "    min(date) as date,\n",
    "    userId,\n",
    "    conversationId,\n",
    "    channel,\n",
    "    botId\n",
    "FROM chatbot_treated\n",
    "WHERE userId NOT IN (SELECT userId FROM users_to_filter)\n",
    "GROUP BY 2,3,4,5\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    users.date,\n",
    "    users.userId,\n",
    "    users.conversationId,\n",
    "    channel,\n",
    "    pokemon_list AS favourite_pokemon,\n",
    "    age,\n",
    "    city,\n",
    "    botId\n",
    "FROM \n",
    "    users\n",
    "LEFT JOIN pokemon_treated ON users.userId = pokemon_treated.userId\n",
    "LEFT JOIN age ON users.userId = age.userId\n",
    "LEFT JOIN city ON users.userId = city.userId\n",
    "\"\"\")\n",
    "\n",
    "final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49996"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expected, we have 4 users less than the original 50000. \n",
    "\n",
    "Now, we save the data in `parquet`. Before that, lets see how much partitions our `final` dataframe have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. Since the data itself is small, we will reduce to one partition in order to save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final.coalesce(1).write.parquet(\"/app/files/treated_data\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we stop our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "56505187a8efebe3b59562d2dd89956d7693816b55ae00defc6a30e0a6d8c2e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
